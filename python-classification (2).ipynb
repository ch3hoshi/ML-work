{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8393208,"sourceType":"datasetVersion","datasetId":4992893}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"贾轩茗 金融学 202111030026","metadata":{}},{"cell_type":"code","source":"pip install feature_engine","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport feature_engine\nimport seaborn as sns\nfrom pandas import Series,DataFrame\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler # 标准化\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import r2_score, mean_squared_error, accuracy_score\nfrom sklearn.model_selection import KFold, GridSearchCV, ShuffleSplit, cross_val_score, cross_validate\nfrom sklearn.compose import ColumnTransformer\nfrom feature_engine.encoding import OneHotEncoder # 分类变量数值化","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T14:48:30.355288Z","iopub.execute_input":"2024-05-13T14:48:30.355682Z","iopub.status.idle":"2024-05-13T14:48:33.309474Z","shell.execute_reply.started":"2024-05-13T14:48:30.355650Z","shell.execute_reply":"2024-05-13T14:48:33.307898Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/classification/asap-bnu-train-4.csv')\nprint(train.shape)\ntest = pd.read_csv('/kaggle/input/classification/asap-bnu-test-4-features.csv')\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:37.110668Z","iopub.execute_input":"2024-05-13T14:48:37.111494Z","iopub.status.idle":"2024-05-13T14:48:37.170985Z","shell.execute_reply.started":"2024-05-13T14:48:37.111457Z","shell.execute_reply":"2024-05-13T14:48:37.169206Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(1416, 28)\n(354, 27)\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:41.985045Z","iopub.execute_input":"2024-05-13T14:48:41.985456Z","iopub.status.idle":"2024-05-13T14:48:42.014702Z","shell.execute_reply.started":"2024-05-13T14:48:41.985426Z","shell.execute_reply":"2024-05-13T14:48:42.013067Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  essay_id  score         genre  sent_num  max_depth  mean_depth  num_word  \\\n0  DMsvCCW      0  source-based         2          4    4.000000      24.0   \n1  Oq55l8p      1  source-based         1          1    1.000000       2.0   \n2  cDXkupP      2  source-based         7          8    5.857143     150.0   \n3  6wPJQmo      2  source-based         9          7    4.888889     145.0   \n4  zJzoiGC      3  source-based        10          8    5.100000     230.0   \n\n   num_unique_word  num_noun  num_unique_noun  ...  num_special_token  \\\n0             17.0       2.0              2.0  ...                2.0   \n1              2.0       1.0              1.0  ...                0.0   \n2             85.0      27.0             19.0  ...               13.0   \n3             79.0      22.0             16.0  ...                9.0   \n4            100.0      36.0             24.0  ...               16.0   \n\n   num_unique_special_token  num_unique_lemma  mean_word_length  \\\n0                       1.0              17.0          3.083333   \n1                       0.0               2.0          3.000000   \n2                       2.0              84.0          3.233333   \n3                       1.0              73.0          3.255172   \n4                       2.0              90.0          3.247826   \n\n   mean_sent_length  bigram_lemma_ttr  trigram_lemma_ttr  task_fulfillment  \\\n0         11.000000          0.954545           1.000000         partially   \n1          2.000000          1.000000           1.000000         partially   \n2         22.666667          0.897810           0.977941         partially   \n3         15.000000          0.888060           0.962406         partially   \n4         21.400000          0.812207           0.933962            mostly   \n\n   depth_variation_level  error_density  \n0                  small         medium  \n1                  small            low  \n2                  large         medium  \n3                  large            low  \n4                  large            low  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>score</th>\n      <th>genre</th>\n      <th>sent_num</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>num_word</th>\n      <th>num_unique_word</th>\n      <th>num_noun</th>\n      <th>num_unique_noun</th>\n      <th>...</th>\n      <th>num_special_token</th>\n      <th>num_unique_special_token</th>\n      <th>num_unique_lemma</th>\n      <th>mean_word_length</th>\n      <th>mean_sent_length</th>\n      <th>bigram_lemma_ttr</th>\n      <th>trigram_lemma_ttr</th>\n      <th>task_fulfillment</th>\n      <th>depth_variation_level</th>\n      <th>error_density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DMsvCCW</td>\n      <td>0</td>\n      <td>source-based</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4.000000</td>\n      <td>24.0</td>\n      <td>17.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>17.0</td>\n      <td>3.083333</td>\n      <td>11.000000</td>\n      <td>0.954545</td>\n      <td>1.000000</td>\n      <td>partially</td>\n      <td>small</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oq55l8p</td>\n      <td>1</td>\n      <td>source-based</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>partially</td>\n      <td>small</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cDXkupP</td>\n      <td>2</td>\n      <td>source-based</td>\n      <td>7</td>\n      <td>8</td>\n      <td>5.857143</td>\n      <td>150.0</td>\n      <td>85.0</td>\n      <td>27.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>84.0</td>\n      <td>3.233333</td>\n      <td>22.666667</td>\n      <td>0.897810</td>\n      <td>0.977941</td>\n      <td>partially</td>\n      <td>large</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6wPJQmo</td>\n      <td>2</td>\n      <td>source-based</td>\n      <td>9</td>\n      <td>7</td>\n      <td>4.888889</td>\n      <td>145.0</td>\n      <td>79.0</td>\n      <td>22.0</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>73.0</td>\n      <td>3.255172</td>\n      <td>15.000000</td>\n      <td>0.888060</td>\n      <td>0.962406</td>\n      <td>partially</td>\n      <td>large</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zJzoiGC</td>\n      <td>3</td>\n      <td>source-based</td>\n      <td>10</td>\n      <td>8</td>\n      <td>5.100000</td>\n      <td>230.0</td>\n      <td>100.0</td>\n      <td>36.0</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>16.0</td>\n      <td>2.0</td>\n      <td>90.0</td>\n      <td>3.247826</td>\n      <td>21.400000</td>\n      <td>0.812207</td>\n      <td>0.933962</td>\n      <td>mostly</td>\n      <td>large</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 区分分类和连续变量\ncontinuous_cols = train.columns[3:25]\ncategorical_cols = train.columns[25:].append(train.columns[2:3])\nprint(continuous_cols)\nprint(categorical_cols)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:44.690961Z","iopub.execute_input":"2024-05-13T14:48:44.691352Z","iopub.status.idle":"2024-05-13T14:48:44.700832Z","shell.execute_reply.started":"2024-05-13T14:48:44.691320Z","shell.execute_reply":"2024-05-13T14:48:44.698529Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Index(['sent_num', 'max_depth', 'mean_depth', 'num_word', 'num_unique_word',\n       'num_noun', 'num_unique_noun', 'num_verb', 'num_unique_verb', 'num_adj',\n       'num_unique_adj', 'num_adv', 'num_unique_adv', 'num_pron',\n       'num_unique_pron', 'num_special_token', 'num_unique_special_token',\n       'num_unique_lemma', 'mean_word_length', 'mean_sent_length',\n       'bigram_lemma_ttr', 'trigram_lemma_ttr'],\n      dtype='object')\nIndex(['task_fulfillment', 'depth_variation_level', 'error_density', 'genre'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabel_train = pd.DataFrame([])\nlabel_test = pd.DataFrame([])\n\nfor feature in categorical_cols:\n    le.fit(train[feature])\n    label_train[feature] = le.transform(train[feature])\n    label_test[feature] = le.transform(test[feature])\n    \nlabel_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:47.140428Z","iopub.execute_input":"2024-05-13T14:48:47.140855Z","iopub.status.idle":"2024-05-13T14:48:47.165858Z","shell.execute_reply.started":"2024-05-13T14:48:47.140826Z","shell.execute_reply":"2024-05-13T14:48:47.164586Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   task_fulfillment  depth_variation_level  error_density  genre\n0                 3                      1              2      0\n1                 3                      1              1      0\n2                 3                      0              2      0\n3                 3                      0              1      0\n4                 2                      0              1      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_fulfillment</th>\n      <th>depth_variation_level</th>\n      <th>error_density</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"scaler = StandardScaler()\nscale_train = scaler.fit_transform(pd.DataFrame(train[continuous_cols]))\nscale_test = scaler.fit_transform(pd.DataFrame(test[continuous_cols]))\nscale_train_df = pd.DataFrame(scale_train, columns=continuous_cols)\nscale_test_df = pd.DataFrame(scale_test, columns=continuous_cols)\nscale_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:49.946888Z","iopub.execute_input":"2024-05-13T14:48:49.947729Z","iopub.status.idle":"2024-05-13T14:48:49.986470Z","shell.execute_reply.started":"2024-05-13T14:48:49.947690Z","shell.execute_reply":"2024-05-13T14:48:49.985202Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   sent_num  max_depth  mean_depth  num_word  num_unique_word  num_noun  \\\n0 -1.002190  -1.628956   -0.908143 -1.399836        -1.660632 -1.509268   \n1 -1.343730  -3.079649   -2.959450 -1.780277        -2.235045 -1.603522   \n2  0.705513   0.305301    0.361714  0.779054         0.943373  0.847091   \n3  1.388593  -0.178263   -0.300348  0.692590         0.713608  0.375819   \n4  1.730134   0.305301   -0.155997  2.162476         1.517786  1.695380   \n\n   num_unique_noun  num_verb  num_unique_verb   num_adj  ...  num_unique_adv  \\\n0        -1.626923 -1.492251        -1.513569 -0.863678  ...       -1.098435   \n1        -1.770933 -1.842379        -1.932029 -1.114389  ...       -1.424511   \n2         0.821242  0.491812         0.439245  0.891298  ...        0.858023   \n3         0.389213  0.608522         0.718219  1.142009  ...       -0.120206   \n4         1.541290  2.009037         1.415652  1.894142  ...        1.184099   \n\n   num_pron  num_unique_pron  num_special_token  num_unique_special_token  \\\n0 -0.947649        -1.427843          -0.986592                 -1.016585   \n1 -1.664230        -2.275569          -1.314799                 -1.870371   \n2  1.345412         1.539197           0.818548                 -0.162798   \n3  0.485514         0.691471           0.162133                 -1.016585   \n4  0.915463         0.691471           1.310858                 -0.162798   \n\n   num_unique_lemma  mean_word_length  mean_sent_length  bigram_lemma_ttr  \\\n0         -1.669891         -1.176287         -1.143656          0.639648   \n1         -2.285503         -1.752763         -2.083700          1.395845   \n2          1.079843         -0.138631          0.074919         -0.304218   \n3          0.628394          0.012445         -0.725859         -0.466431   \n4          1.326087         -0.038374         -0.057384         -1.728348   \n\n   trigram_lemma_ttr  \n0           0.683305  \n1           0.683305  \n2           0.120557  \n3          -0.275765  \n4          -1.001400  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_num</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>num_word</th>\n      <th>num_unique_word</th>\n      <th>num_noun</th>\n      <th>num_unique_noun</th>\n      <th>num_verb</th>\n      <th>num_unique_verb</th>\n      <th>num_adj</th>\n      <th>...</th>\n      <th>num_unique_adv</th>\n      <th>num_pron</th>\n      <th>num_unique_pron</th>\n      <th>num_special_token</th>\n      <th>num_unique_special_token</th>\n      <th>num_unique_lemma</th>\n      <th>mean_word_length</th>\n      <th>mean_sent_length</th>\n      <th>bigram_lemma_ttr</th>\n      <th>trigram_lemma_ttr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.002190</td>\n      <td>-1.628956</td>\n      <td>-0.908143</td>\n      <td>-1.399836</td>\n      <td>-1.660632</td>\n      <td>-1.509268</td>\n      <td>-1.626923</td>\n      <td>-1.492251</td>\n      <td>-1.513569</td>\n      <td>-0.863678</td>\n      <td>...</td>\n      <td>-1.098435</td>\n      <td>-0.947649</td>\n      <td>-1.427843</td>\n      <td>-0.986592</td>\n      <td>-1.016585</td>\n      <td>-1.669891</td>\n      <td>-1.176287</td>\n      <td>-1.143656</td>\n      <td>0.639648</td>\n      <td>0.683305</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.343730</td>\n      <td>-3.079649</td>\n      <td>-2.959450</td>\n      <td>-1.780277</td>\n      <td>-2.235045</td>\n      <td>-1.603522</td>\n      <td>-1.770933</td>\n      <td>-1.842379</td>\n      <td>-1.932029</td>\n      <td>-1.114389</td>\n      <td>...</td>\n      <td>-1.424511</td>\n      <td>-1.664230</td>\n      <td>-2.275569</td>\n      <td>-1.314799</td>\n      <td>-1.870371</td>\n      <td>-2.285503</td>\n      <td>-1.752763</td>\n      <td>-2.083700</td>\n      <td>1.395845</td>\n      <td>0.683305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.705513</td>\n      <td>0.305301</td>\n      <td>0.361714</td>\n      <td>0.779054</td>\n      <td>0.943373</td>\n      <td>0.847091</td>\n      <td>0.821242</td>\n      <td>0.491812</td>\n      <td>0.439245</td>\n      <td>0.891298</td>\n      <td>...</td>\n      <td>0.858023</td>\n      <td>1.345412</td>\n      <td>1.539197</td>\n      <td>0.818548</td>\n      <td>-0.162798</td>\n      <td>1.079843</td>\n      <td>-0.138631</td>\n      <td>0.074919</td>\n      <td>-0.304218</td>\n      <td>0.120557</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.388593</td>\n      <td>-0.178263</td>\n      <td>-0.300348</td>\n      <td>0.692590</td>\n      <td>0.713608</td>\n      <td>0.375819</td>\n      <td>0.389213</td>\n      <td>0.608522</td>\n      <td>0.718219</td>\n      <td>1.142009</td>\n      <td>...</td>\n      <td>-0.120206</td>\n      <td>0.485514</td>\n      <td>0.691471</td>\n      <td>0.162133</td>\n      <td>-1.016585</td>\n      <td>0.628394</td>\n      <td>0.012445</td>\n      <td>-0.725859</td>\n      <td>-0.466431</td>\n      <td>-0.275765</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.730134</td>\n      <td>0.305301</td>\n      <td>-0.155997</td>\n      <td>2.162476</td>\n      <td>1.517786</td>\n      <td>1.695380</td>\n      <td>1.541290</td>\n      <td>2.009037</td>\n      <td>1.415652</td>\n      <td>1.894142</td>\n      <td>...</td>\n      <td>1.184099</td>\n      <td>0.915463</td>\n      <td>0.691471</td>\n      <td>1.310858</td>\n      <td>-0.162798</td>\n      <td>1.326087</td>\n      <td>-0.038374</td>\n      <td>-0.057384</td>\n      <td>-1.728348</td>\n      <td>-1.001400</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_features = pd.concat([scale_train_df, label_train], axis=1)\ntest_features = pd.concat([scale_test_df, label_test], axis=1)\nprint(train_features.shape)\nprint(test_features.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:48:58.300581Z","iopub.execute_input":"2024-05-13T14:48:58.300953Z","iopub.status.idle":"2024-05-13T14:48:58.311343Z","shell.execute_reply.started":"2024-05-13T14:48:58.300925Z","shell.execute_reply":"2024-05-13T14:48:58.310051Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(1416, 26)\n(354, 26)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_score = train['score']\ntrain1 = pd.concat([train_score,train_features], axis=1)\ntrain_data, validate_data = train_test_split(train1, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:00.773134Z","iopub.execute_input":"2024-05-13T14:49:00.773549Z","iopub.status.idle":"2024-05-13T14:49:00.788564Z","shell.execute_reply.started":"2024-05-13T14:49:00.773516Z","shell.execute_reply":"2024-05-13T14:49:00.787317Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:02.767677Z","iopub.execute_input":"2024-05-13T14:49:02.768079Z","iopub.status.idle":"2024-05-13T14:49:02.860880Z","shell.execute_reply.started":"2024-05-13T14:49:02.768049Z","shell.execute_reply":"2024-05-13T14:49:02.859057Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"             score     sent_num    max_depth   mean_depth     num_word  \\\ncount  1132.000000  1132.000000  1132.000000  1132.000000  1132.000000   \nmean      1.432862    -0.022825    -0.017217     0.010287    -0.013786   \nstd       0.947750     0.994541     0.997587     1.026220     0.990746   \nmin       0.000000    -1.343730    -3.079649    -2.959450    -1.780277   \n25%       1.000000    -0.660649    -0.661827    -0.634635    -0.794588   \n50%       1.000000    -0.319109    -0.178263    -0.148399    -0.154756   \n75%       2.000000     0.705513     0.305301     0.459396     0.640712   \nmax       3.000000     5.487078     6.591636     6.613318     3.805290   \n\n       num_unique_word     num_noun  num_unique_noun     num_verb  \\\ncount      1132.000000  1132.000000      1132.000000  1132.000000   \nmean         -0.019158    -0.007526        -0.011012    -0.015545   \nstd           0.989119     0.993379         0.987297     0.989015   \nmin          -2.235045    -1.697776        -1.914943    -1.842379   \n25%          -0.818160    -0.755233        -0.762865    -0.791993   \n50%          -0.109717    -0.189707        -0.186826    -0.208445   \n75%           0.637020     0.564328         0.677232     0.608522   \nmax           3.470790     3.863230         4.133465     4.226519   \n\n       num_unique_verb  ...  num_unique_special_token  num_unique_lemma  \\\ncount      1132.000000  ...               1132.000000       1132.000000   \nmean         -0.017290  ...                 -0.011953         -0.018796   \nstd           0.986849  ...                  1.003577          0.989052   \nmin          -1.932029  ...                 -1.870371         -2.285503   \n25%          -0.816135  ...                 -1.016585         -0.808034   \n50%          -0.118702  ...                 -0.162798         -0.110341   \n75%           0.578732  ...                  0.690988          0.628394   \nmax           4.065900  ...                  4.959920          3.419168   \n\n       mean_word_length  mean_sent_length  bigram_lemma_ttr  \\\ncount       1132.000000       1132.000000       1132.000000   \nmean           0.011319          0.021987         -0.004564   \nstd            1.006895          1.021440          1.018620   \nmin           -8.737634         -2.083700         -7.920499   \n25%           -0.429596         -0.621410         -0.543686   \n50%            0.021008         -0.203613          0.100708   \n75%            0.585472          0.353450          0.703562   \nmax            3.781404          8.465678          1.395845   \n\n       trigram_lemma_ttr  task_fulfillment  depth_variation_level  \\\ncount        1132.000000       1132.000000            1132.000000   \nmean           -0.003620          2.500000               0.526502   \nstd             1.042801          0.952914               0.499518   \nmin           -11.984346          0.000000               0.000000   \n25%            -0.290407          2.000000               0.000000   \n50%             0.284692          3.000000               1.000000   \n75%             0.683305          3.000000               1.000000   \nmax             0.683305          3.000000               1.000000   \n\n       error_density   genre  \ncount    1132.000000  1132.0  \nmean        1.387809     0.0  \nstd         0.764342     0.0  \nmin         0.000000     0.0  \n25%         1.000000     0.0  \n50%         2.000000     0.0  \n75%         2.000000     0.0  \nmax         2.000000     0.0  \n\n[8 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>sent_num</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>num_word</th>\n      <th>num_unique_word</th>\n      <th>num_noun</th>\n      <th>num_unique_noun</th>\n      <th>num_verb</th>\n      <th>num_unique_verb</th>\n      <th>...</th>\n      <th>num_unique_special_token</th>\n      <th>num_unique_lemma</th>\n      <th>mean_word_length</th>\n      <th>mean_sent_length</th>\n      <th>bigram_lemma_ttr</th>\n      <th>trigram_lemma_ttr</th>\n      <th>task_fulfillment</th>\n      <th>depth_variation_level</th>\n      <th>error_density</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>...</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.000000</td>\n      <td>1132.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.432862</td>\n      <td>-0.022825</td>\n      <td>-0.017217</td>\n      <td>0.010287</td>\n      <td>-0.013786</td>\n      <td>-0.019158</td>\n      <td>-0.007526</td>\n      <td>-0.011012</td>\n      <td>-0.015545</td>\n      <td>-0.017290</td>\n      <td>...</td>\n      <td>-0.011953</td>\n      <td>-0.018796</td>\n      <td>0.011319</td>\n      <td>0.021987</td>\n      <td>-0.004564</td>\n      <td>-0.003620</td>\n      <td>2.500000</td>\n      <td>0.526502</td>\n      <td>1.387809</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.947750</td>\n      <td>0.994541</td>\n      <td>0.997587</td>\n      <td>1.026220</td>\n      <td>0.990746</td>\n      <td>0.989119</td>\n      <td>0.993379</td>\n      <td>0.987297</td>\n      <td>0.989015</td>\n      <td>0.986849</td>\n      <td>...</td>\n      <td>1.003577</td>\n      <td>0.989052</td>\n      <td>1.006895</td>\n      <td>1.021440</td>\n      <td>1.018620</td>\n      <td>1.042801</td>\n      <td>0.952914</td>\n      <td>0.499518</td>\n      <td>0.764342</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-1.343730</td>\n      <td>-3.079649</td>\n      <td>-2.959450</td>\n      <td>-1.780277</td>\n      <td>-2.235045</td>\n      <td>-1.697776</td>\n      <td>-1.914943</td>\n      <td>-1.842379</td>\n      <td>-1.932029</td>\n      <td>...</td>\n      <td>-1.870371</td>\n      <td>-2.285503</td>\n      <td>-8.737634</td>\n      <td>-2.083700</td>\n      <td>-7.920499</td>\n      <td>-11.984346</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>-0.660649</td>\n      <td>-0.661827</td>\n      <td>-0.634635</td>\n      <td>-0.794588</td>\n      <td>-0.818160</td>\n      <td>-0.755233</td>\n      <td>-0.762865</td>\n      <td>-0.791993</td>\n      <td>-0.816135</td>\n      <td>...</td>\n      <td>-1.016585</td>\n      <td>-0.808034</td>\n      <td>-0.429596</td>\n      <td>-0.621410</td>\n      <td>-0.543686</td>\n      <td>-0.290407</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>-0.319109</td>\n      <td>-0.178263</td>\n      <td>-0.148399</td>\n      <td>-0.154756</td>\n      <td>-0.109717</td>\n      <td>-0.189707</td>\n      <td>-0.186826</td>\n      <td>-0.208445</td>\n      <td>-0.118702</td>\n      <td>...</td>\n      <td>-0.162798</td>\n      <td>-0.110341</td>\n      <td>0.021008</td>\n      <td>-0.203613</td>\n      <td>0.100708</td>\n      <td>0.284692</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>0.705513</td>\n      <td>0.305301</td>\n      <td>0.459396</td>\n      <td>0.640712</td>\n      <td>0.637020</td>\n      <td>0.564328</td>\n      <td>0.677232</td>\n      <td>0.608522</td>\n      <td>0.578732</td>\n      <td>...</td>\n      <td>0.690988</td>\n      <td>0.628394</td>\n      <td>0.585472</td>\n      <td>0.353450</td>\n      <td>0.703562</td>\n      <td>0.683305</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.000000</td>\n      <td>5.487078</td>\n      <td>6.591636</td>\n      <td>6.613318</td>\n      <td>3.805290</td>\n      <td>3.470790</td>\n      <td>3.863230</td>\n      <td>4.133465</td>\n      <td>4.226519</td>\n      <td>4.065900</td>\n      <td>...</td>\n      <td>4.959920</td>\n      <td>3.419168</td>\n      <td>3.781404</td>\n      <td>8.465678</td>\n      <td>1.395845</td>\n      <td>0.683305</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"correlation_matrix = train_data.corr()\nplt.figure(figsize=(20, 18))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 4))\nplt.hist(train_data['score'])\nplt.title(\"Train data - score\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.hist(figsize=(12, 10), color='blue', edgecolor='black',bins=50)\nplt.gcf().set_facecolor('lightgrey')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features=[\n    'num_word',\n    'bigram_lemma_ttr',\n    'mean_sent_length',\n    'task_fulfillment',    \n    'depth_variation_level'\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:26.083964Z","iopub.execute_input":"2024-05-13T14:49:26.084350Z","iopub.status.idle":"2024-05-13T14:49:26.090019Z","shell.execute_reply.started":"2024-05-13T14:49:26.084321Z","shell.execute_reply":"2024-05-13T14:49:26.088693Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"selected_features = train_features.columns\nselected_features = selected_features.drop('genre')\nselected_features","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:20.066510Z","iopub.execute_input":"2024-05-13T14:49:20.066891Z","iopub.status.idle":"2024-05-13T14:49:20.075589Z","shell.execute_reply.started":"2024-05-13T14:49:20.066863Z","shell.execute_reply":"2024-05-13T14:49:20.074239Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Index(['sent_num', 'max_depth', 'mean_depth', 'num_word', 'num_unique_word',\n       'num_noun', 'num_unique_noun', 'num_verb', 'num_unique_verb', 'num_adj',\n       'num_unique_adj', 'num_adv', 'num_unique_adv', 'num_pron',\n       'num_unique_pron', 'num_special_token', 'num_unique_special_token',\n       'num_unique_lemma', 'mean_word_length', 'mean_sent_length',\n       'bigram_lemma_ttr', 'trigram_lemma_ttr', 'task_fulfillment',\n       'depth_variation_level', 'error_density'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"train_data_use = train_data[selected_features]\nvalidate_data_use = validate_data[selected_features]\ntest_data_use = test_features[selected_features]\ntrain_data_use.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:28.744939Z","iopub.execute_input":"2024-05-13T14:49:28.745402Z","iopub.status.idle":"2024-05-13T14:49:28.765483Z","shell.execute_reply.started":"2024-05-13T14:49:28.745355Z","shell.execute_reply":"2024-05-13T14:49:28.763568Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"     num_word  bigram_lemma_ttr  mean_sent_length  task_fulfillment  \\\n767 -0.293098          0.771983         -1.083971                 3   \n486 -1.469007          1.395845         -0.308062                 3   \n48   1.626400         -0.414325          2.694855                 3   \n155 -0.932931          0.716811          0.214184                 0   \n584 -0.984809          1.395845          2.512069                 3   \n\n     depth_variation_level  \n767                      0  \n486                      1  \n48                       1  \n155                      0  \n584                      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_word</th>\n      <th>bigram_lemma_ttr</th>\n      <th>mean_sent_length</th>\n      <th>task_fulfillment</th>\n      <th>depth_variation_level</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>767</th>\n      <td>-0.293098</td>\n      <td>0.771983</td>\n      <td>-1.083971</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>486</th>\n      <td>-1.469007</td>\n      <td>1.395845</td>\n      <td>-0.308062</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1.626400</td>\n      <td>-0.414325</td>\n      <td>2.694855</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>-0.932931</td>\n      <td>0.716811</td>\n      <td>0.214184</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>-0.984809</td>\n      <td>1.395845</td>\n      <td>2.512069</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.multiclass import OneVsRestClassifier","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:49:32.501501Z","iopub.execute_input":"2024-05-13T14:49:32.501909Z","iopub.status.idle":"2024-05-13T14:49:32.738879Z","shell.execute_reply.started":"2024-05-13T14:49:32.501876Z","shell.execute_reply":"2024-05-13T14:49:32.737502Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# 定义分类模型\nlogistic_model = LogisticRegression(random_state=42, multi_class='auto')\nrf_model = RandomForestClassifier(random_state=42)\ndecisiontree_model = DecisionTreeClassifier(random_state=42)\nsvm_model = OneVsRestClassifier(SVC(probability=True))\nnaiveB_model = GaussianNB()\ngbtree_model = GradientBoostingClassifier(random_state=42)\nnn_model = MLPClassifier(random_state=42)\nxgb_model = xgb.XGBClassifier(random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:51:02.237697Z","iopub.execute_input":"2024-05-13T14:51:02.238407Z","iopub.status.idle":"2024-05-13T14:51:02.245275Z","shell.execute_reply.started":"2024-05-13T14:51:02.238356Z","shell.execute_reply":"2024-05-13T14:51:02.244091Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\n# 重新定义交叉验证函数，计算QWK分数\ndef cv_scores(model, x, y, cv=10):\n    cv_scores = cross_val_score(model, x, y, cv=cv, scoring='accuracy')\n    qwk_scores = []\n    for i, (train_index, test_index) in enumerate(KFold(n_splits=cv).split(x)):\n        x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        model.fit(x_train, y_train)\n        pred = model.predict(x_test)\n        qwk_score = cohen_kappa_score(y_test, pred, weights='quadratic')\n        qwk_scores.append(qwk_score)\n        print(f\"CV {i+1} QWK Score: {qwk_score}\")\n    return qwk_scores","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:51:07.141350Z","iopub.execute_input":"2024-05-13T14:51:07.141751Z","iopub.status.idle":"2024-05-13T14:51:07.150817Z","shell.execute_reply.started":"2024-05-13T14:51:07.141721Z","shell.execute_reply":"2024-05-13T14:51:07.149274Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_list = [\n    logistic_model,\n    rf_model,\n    decisiontree_model, \n    svm_model, \n    naiveB_model,\n    gbtree_model,\n    nn_model,\n    xgb_model\n]\n\nbest_model = None\nbest_qwk = 0.0\n\nfor model in model_list:\n    model.fit(train_data_use, train_data['score'])\n    print(str(model) + \"训练集表现：\")\n    cv_scores(model, train_data_use, train_data['score'])\n    pred = model.predict(validate_data_use)\n    qwk = cohen_kappa_score(validate_data['score'], pred, weights='quadratic')\n    accuracy = accuracy_score(validate_data['score'], pred)\n    print(str(model) + \"验证集表现：\")\n    print(\"QWK Score:\", qwk)\n    print(\"Accuracy:\", accuracy)\n    \n    if qwk > best_qwk:\n        best_qwk = qwk\n        best_model = model\n\nprint(\"最佳模型：\", best_model)\nprint(\"最佳模型验证集QWK：\", best_qwk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 参数调优","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import cohen_kappa_score\n\n# 重新定义QWK评分函数\ndef qwk_scorer(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n\nlogistic_model = LogisticRegression(random_state=42, multi_class='auto')\nparam_grid = {\n    'C': [0.1, 1, 10],  # 正则化参数\n    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # 求解器\n    'max_iter': [100, 200, 300]  # 最大迭代次数\n}\n\n# 交叉验证获得最佳参数\n\ngrid_search_logistic = GridSearchCV(estimator=logistic_model, param_grid=param_grid, cv=10, scoring=make_scorer(qwk_scorer))\ngrid_search_logistic.fit(train_data_use, train_data['score'])\nprint(\"最佳参数：\", grid_search_logistic.best_params_)\nprint(\"最佳得分：\", grid_search_logistic.best_score_)\n\n# 使用最佳参数的模型进行预测\nbest_logistic_model = grid_search_logistic.best_estimator_\npred_logistic = best_logistic_model.predict(validate_data_use)\n\n# 计算QWK\nqwk_logistic = qwk_scorer(validate_data['score'], pred_logistic)\nprint(\"Logistic回归验证集QWK：\", qwk_logistic)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:53:40.668204Z","iopub.execute_input":"2024-05-13T14:53:40.668688Z","iopub.status.idle":"2024-05-13T14:53:49.367869Z","shell.execute_reply.started":"2024-05-13T14:53:40.668627Z","shell.execute_reply":"2024-05-13T14:53:49.366478Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"最佳参数： {'C': 1, 'max_iter': 100, 'solver': 'liblinear'}\n最佳得分： 0.7328732196413743\nLogistic回归验证集QWK： 0.7056801171226004\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\nsvc_model = SVC()\n\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'kernel': ['linear', 'rbf', 'poly'],\n    'gamma': ['scale', 'auto']\n}\n\ngrid_search_svc = GridSearchCV(estimator=svc_model, param_grid=param_grid, cv=10, scoring='accuracy')\ngrid_search_svc.fit(train_data_use, train_data['score'])\nprint(\"最佳参数：\", grid_search_svc.best_params_)\nprint(\"最佳得分：\", grid_search_svc.best_score_)\n\n# 使用最佳参数的模型进行预测\nbest_svc_model = grid_search_svc.best_estimator_\npred_svc = best_svc_model.predict(validate_data_use)\naccuracy_svc = accuracy_score(validate_data['score'], pred_svc)\nprint(\"svc验证集表现：\", accuracy_svc)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T15:52:33.912471Z","iopub.execute_input":"2024-05-13T15:52:33.912946Z","iopub.status.idle":"2024-05-13T15:52:48.701510Z","shell.execute_reply.started":"2024-05-13T15:52:33.912909Z","shell.execute_reply":"2024-05-13T15:52:48.700309Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"最佳参数： {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n最佳得分： 0.666953889147648\nsvc验证集表现： 0.6514084507042254\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import accuracy_score\n\nsvc_model = SVC()\n\novr_model = OneVsRestClassifier(svc_model)\n\npipeline = Pipeline([('classifier', ovr_model)])\n\nparam_grid = {\n    'classifier__estimator__C': [0.1, 1, 10],\n    'classifier__estimator__kernel': ['linear', 'rbf', 'poly'],\n    'classifier__estimator__gamma': ['scale', 'auto']\n}\n\ngrid_search_svc = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, scoring='accuracy')\ngrid_search_svc.fit(train_data_use, train_data['score'])\nprint(\"最佳参数：\", grid_search_svc.best_params_)\nprint(\"最佳得分：\", grid_search_svc.best_score_)\n\n# 使用最佳参数的模型进行预测\nbest_svc_model = grid_search_svc.best_estimator_\npred_svc = best_svc_model.predict(validate_data_use)\naccuracy_svc = accuracy_score(validate_data['score'], pred_svc)\nprint(\"svc验证集表现：\", accuracy_svc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\ngb_model = GradientBoostingClassifier()\n\nparam_grid = {\n    'learning_rate': [0.1, 0.05, 0.01],\n    'n_estimators': [50, 100, 200],\n    'max_depth': [3, 4, 5]\n}\n\ngrid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=10, scoring=make_scorer(qwk_scorer))\ngrid_search_gb.fit(train_data_use, train_data['score'])\nprint(\"最佳参数：\", grid_search_gb.best_params_)\nprint(\"最佳得分：\", grid_search_gb.best_score_)\n\nbest_gb_model = grid_search_gb.best_estimator_\npred_gb = best_gb_model.predict(validate_data_use)\nqwk_gb = qwk_scorer(validate_data['score'], pred_gb)\nprint(\"梯度提升验证集QWK：\", qwk_gb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_clf = xgb.XGBClassifier()\n\nparam_grid = {\n    'learning_rate': [0.1, 0.01, 0.001],  # 学习率\n    'n_estimators': [50, 100, 200],  # 迭代次数\n    'max_depth': [3, 4, 5],  # 树的最大深度\n    'min_child_weight': [1, 2, 3]  # 叶子节点最小权重\n}\n\ngrid_search_xgb = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, cv=5, scoring='accuracy')\ngrid_search_xgb.fit(train_data_use, train_data['score'])\nprint(\"最佳参数：\", grid_search_xgb.best_params_)\nprint(\"最佳得分：\", grid_search_xgb.best_score_)\n\n# 使用最佳参数的模型进行预测\nbest_xgb_model = grid_search_xgb.best_estimator_\ny_pred = best_xgb_model.predict(validate_data_use)\naccuracy = accuracy_score(validate_data['score'], y_pred)\nprint(\"验证集表现：\", accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 测试集预测","metadata":{}},{"cell_type":"code","source":"pred_test = best_svc_model.predict(test_data_use)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:54:14.775874Z","iopub.execute_input":"2024-05-13T14:54:14.776270Z","iopub.status.idle":"2024-05-13T14:54:14.783611Z","shell.execute_reply.started":"2024-05-13T14:54:14.776231Z","shell.execute_reply":"2024-05-13T14:54:14.782222Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"output_dict = {\n    'essay_id': test['essay_id'],\n    'score': pred_test\n}\noutput_df = pd.DataFrame(output_dict)\noutput_df.to_csv(\"/kaggle/working/submission_svc.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T14:54:21.971590Z","iopub.execute_input":"2024-05-13T14:54:21.973036Z","iopub.status.idle":"2024-05-13T14:54:21.986826Z","shell.execute_reply.started":"2024-05-13T14:54:21.972970Z","shell.execute_reply":"2024-05-13T14:54:21.985162Z"},"trusted":true},"execution_count":20,"outputs":[]}]}